# Flink数据倾斜的解决方法

在Flink实时计算的任务中,一个最常见的场景就是分组聚合,但是当key数量很少的时候就会发生数据倾斜,最近的一个任务就出现了这个问题,造成的结果就是反压,这个时候增加并发度是没有用的,因为key的个数没有变,还会造成ck超时失败.

如果只有一个key,key的数量远远小于并发实例的个数,所以只有一个并发在工作,其他的都是空闲的,不能很好的利用分布式,也浪费了大量的资源,在Flink里面怎么解决这个问题呢?

解决数据倾斜的核心就是打散key

不管是在spark还是flink里面都会遇到数据倾斜的问题,一种最常用的方式是给key加随机数,然后分开两次聚合,在spark里面经常这样解决,那Flink里面具体怎么实现呢?

数据倾斜前的代码我就不在贴了,非常的简单,直接贴一下解决后的代码,就是在分组前先给key加一个随机的前缀,聚合后把随机的前缀去掉,然后再聚合一次。
